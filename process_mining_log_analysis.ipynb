{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import pandas\n",
    "\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.log.obj import EventLog\n",
    "\n",
    "# Step 1: Read and combine the two log files into one log\n",
    "log_part_1 = xes_importer.apply(\"Road_Traffic_Fine_Management_Process_Data/Road_Traffic_Fine_Management_Process_Part1.xes\")\n",
    "log_part_2 = xes_importer.apply(\"Road_Traffic_Fine_Management_Process_Data/Road_Traffic_Fine_Management_Process_Part2.xes\")\n",
    "log = EventLog(list(log_part_1) + list(log_part_2))\n",
    "log_df = pm4py.convert_to_dataframe(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 2: Inspect the Loaded Log\n",
    "print(f\"Number of traces in the log: {len(log)}\\n\\n\")\n",
    "print(f\"Details of the first log (log[0]):\\n{log[0]}\\n\\n\")\n",
    "print(f\"Details of the first event in the first log (log[0][0]):\\n{log[0][0]}\\n\\n\")\n",
    "print(f\"Starting activities and their count for all traces: \\n{pm4py.get_start_activities(log)}\\n\\n\")\n",
    "end_activities = pm4py.get_end_activities(log)\n",
    "print(f\"End activities and their count for all traces: \\n{end_activities}\\n\\n\")\n",
    "end_activities_counter = 0\n",
    "iterations = 0\n",
    "for key, value in end_activities.items():\n",
    "     end_activities_counter += value\n",
    "     iterations += 1\n",
    "print(f'There is a total number of {iterations} end activities all activities end as the end activities are called {end_activities_counter} times which is the same number as the numbers of traces the log holds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e272c4097765e106"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bpmn_model = pm4py.discover_bpmn_inductive(log)\n",
    "pm4py.view_bpmn(bpmn_model)\n",
    "\n",
    "petri_net, marking_1, marking_2 = pm4py.discover_petri_net_inductive(log)\n",
    "pm4py.view_petri_net(petri_net)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d91883f295e18fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bpm_model_975 = pm4py.discover_bpmn_inductive(log, 0.025)\n",
    "pm4py.view_bpmn(bpm_model_975)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81de2bf22dc5b5a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#map the traces according to their length\n",
    "print(\"Traces according to their length:\")\n",
    "trace_list_dict = {}\n",
    "for entry in log:\n",
    "    trace_list_dict.setdefault(len(entry), []).append(entry)\n",
    "sorted_trace_list_dict = dict(\n",
    "    sorted(trace_list_dict.items(), key=lambda item: len(item[1]), reverse=True)\n",
    ")\n",
    "trace_count = 0\n",
    "for key, value in sorted_trace_list_dict.items():\n",
    "    trace_count += len(value)\n",
    "    print(f'Number of activities per trace: {key}, number of traces: {len(value)}, % of traces accumulated: {trace_count/len(log)}')\n",
    "\n",
    "print(\"\\n98.9% of all traces are either 2, 5, 6, or 3 event long. Using these to build a petri net we get...\")\n",
    "\n",
    "accumulated_traces_list = list(sorted_trace_list_dict[2]) + list(sorted_trace_list_dict[5]) + list(sorted_trace_list_dict[6]) +list(sorted_trace_list_dict[3])\n",
    "accumulated_trace_log = EventLog(accumulated_traces_list)\n",
    "petri_net_98, m1, m2 = pm4py.discover_petri_net_inductive(accumulated_trace_log)\n",
    "pm4py.view_petri_net(petri_net_98)\n",
    "print(f'Evaluating the petri net; its fittness is: {pm4py.fitness_alignments(log, petri_net_98, m1, m2)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d639c13cfd2738c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using the trace list dict to find happy path\n",
    "log_len_2 = EventLog(trace_list_dict.get(2))\n",
    "bpm_model_2 = pm4py.discover_bpmn_inductive(log_len_2)\n",
    "petri_model_2, m1_2, m2_2 = pm4py.discover_petri_net_inductive(log_len_2)\n",
    "print(pm4py.get_end_activities(log_len_2))\n",
    "pm4py.view_bpmn(bpm_model_2)\n",
    "pm4py.view_petri_net(petri_model_2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd5f43ef9743d89d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_len_5 = EventLog(trace_list_dict.get(5))\n",
    "bpm_model_5 = pm4py.discover_bpmn_inductive(log_len_5)\n",
    "print(pm4py.get_end_activities(log_len_5))\n",
    "pm4py.view_bpmn(bpm_model_5)\n",
    "\n",
    "petri_model_5, m1_5, m2_5 = pm4py.discover_petri_net_inductive(log_len_5)\n",
    "pm4py.view_petri_net(petri_model_5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b30a6b117f2588b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_len_6 = EventLog(trace_list_dict.get(12))\n",
    "bpm_model_6 = pm4py.discover_bpmn_inductive(log_len_6)\n",
    "pm4py.view_bpmn(bpm_model_6)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bdb12410c5f4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_len_3 = EventLog(trace_list_dict.get(3))\n",
    "bpm_model_3 = pm4py.discover_bpmn_inductive(log_len_3)\n",
    "pm4py.view_bpmn(bpm_model_3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa5d8da3a486682"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bpm_model_20 = pm4py.discover_bpmn_inductive(EventLog(trace_list_dict.get(20)))\n",
    "pm4py.view_bpmn(bpm_model_20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f672fadc6ebb0a7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variants = pm4py.stats.get_variants(log_len_5)\n",
    "for key, value in variants.items():\n",
    "     temp_bpmn = pm4py.discover_bpmn_inductive(EventLog(value))\n",
    "     pm4py.view_bpmn(temp_bpmn)\n",
    "print(len(variants))\n",
    "type(variants)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5df7af6c2466fb9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pm4py.objects.log.obj import EventLog, Trace\n",
    "from pm4py.stats import get_variants\n",
    "import pm4py\n",
    "\n",
    "# Get unique variants of traces in the log with their frequencies\n",
    "variants = get_variants(log)\n",
    "counter_trace_list = {str(key): len(value) for key, value in variants.items()}\n",
    "\n",
    "# Sort counter_trace_list by occurrences in descending order\n",
    "sorted_counter_trace_list = dict(sorted(counter_trace_list.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "accumulated_traces = 0\n",
    "total_number_of_traces = len(log)\n",
    "\n",
    "# Discover and view BPMN for each unique variant\n",
    "for trace_sequence, count in sorted_counter_trace_list.items():\n",
    "    # Create an EventLog object with the events in the variant\n",
    "    variant_log = EventLog()\n",
    "    trace = Trace()\n",
    "    for activity in eval(trace_sequence):  # Convert string back to list\n",
    "        trace.append({'concept:name': activity})\n",
    "    variant_log.append(trace)\n",
    "\n",
    "    # Discover BPMN for the variant trace\n",
    "    temp_bpmn = pm4py.discover_bpmn_inductive(variant_log)\n",
    "    pm4py.view_bpmn(temp_bpmn)\n",
    "    accumulated_traces += count\n",
    "    print(f\"Variant {trace_sequence} appears \\n{count} times.\\nPercentage of trace occurence in log:  {count/total_number_of_traces}%\\nAccumulated percentage of trace occurence: {accumulated_traces/total_number_of_traces}\")\n",
    "\n",
    "print(len(variants))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97c5b2403d18ccce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find the top 10 variants that contribute to 98.3% of the log\n",
    "top_10_variants = list(sorted_counter_trace_list.items())[:10]\n",
    "log_98 = EventLog()\n",
    "\n",
    "for trace_sequence, count in top_10_variants:\n",
    "    trace = Trace()\n",
    "    activities = trace_sequence.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    for activity in activities:\n",
    "        trace.append({'concept:name': activity.strip()})\n",
    "    \n",
    "    # Append the trace multiple times to reflect its frequency\n",
    "    for _ in range(count):\n",
    "        log_98.append(trace)\n",
    "\n",
    "# Discover BPMN for the top 10 variants\n",
    "bpmn_98 = pm4py.discover_bpmn_inductive(log_98)\n",
    "pm4py.view_bpmn(bpmn_98)\n",
    "\n",
    "#Discover Petri net for the top 10 variants\n",
    "petri_net_top10, m1_top10, m2_top10 = pm4py.discover_petri_net_inductive(log_98)\n",
    "pm4py.view_petri_net(petri_net_top10)\n",
    "print(f'Evaluating the petri net; its fittness is: {pm4py.fitness_alignments(log, petri_net_top10,m1_top10,m2_top10)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a63ab7b3aacd5db6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Analysis by time (find longest traces)\n",
    "variants_durations = pm4py.get_all_case_durations(log,)\n",
    "print(type(variants_durations))\n",
    "print(variants_durations[1])\n",
    "print(type(variants_durations[0]))\n",
    "len(variants_durations)\n",
    "\n",
    "# Create a dictionary to map case IDs to their durations\n",
    "trace_duration_map = dict()\n",
    "\n",
    "# Iterate through the log to populate the trace-duration map\n",
    "counter = 0\n",
    "for trace in log:\n",
    "    # Use the trace attributes to get the case ID\n",
    "    case_id = trace.attributes.get('concept:name')\n",
    "    if case_id:  # Ensure the case_id exists\n",
    "        # Get the start and end timestamp for the trace\n",
    "        start_time = trace[0]['time:timestamp']\n",
    "        end_time = trace[-1]['time:timestamp']\n",
    "        # Calculate the duration\n",
    "        duration = (end_time - start_time).total_seconds()  # in seconds\n",
    "        # Store in the map\n",
    "        trace_duration_map[case_id] = duration\n",
    "\n",
    "# Display a slice of the trace-duration map\n",
    "print(f' slice of trace_duration map:\\n{({key: trace_duration_map[key] for key in list(trace_duration_map.keys())[150365:150370]})}')\n",
    "\n",
    "print(f'Number of traces: {len(trace_duration_map)}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9191d4552f0c92fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Extract the time values\n",
    "times = list(trace_duration_map.values())\n",
    "\n",
    "# Create the histogram\n",
    "bins = 20  # Number of bins for the histogram\n",
    "hist, bin_edges, patches = plt.hist(times, bins=bins, edgecolor='black')\n",
    "\n",
    "# Annotate with the number of cases\n",
    "for i, count in enumerate(hist):\n",
    "    plt.text(bin_edges[i] + (bin_edges[i+1] - bin_edges[i]) / 2,  # Position at bin center\n",
    "             count + 1,  # Slightly above the bar\n",
    "             int(count),  # Case count as text\n",
    "             ha='center', fontsize=8)\n",
    "\n",
    "# Format x-axis with custom labels\n",
    "def format_duration(seconds):\n",
    "    months = seconds // (30 * 24 * 3600)\n",
    "    days = (seconds % (30 * 24 * 3600)) // (24 * 3600)\n",
    "    return f\"{int(months)}m {int(days)}d\"\n",
    "\n",
    "bin_labels = [format_duration(edge) for edge in bin_edges]\n",
    "plt.xticks(ticks=bin_edges, labels=bin_labels, rotation=45, fontsize=8)\n",
    "\n",
    "plt.title(\"Trace Duration Distribution\")\n",
    "plt.xlabel(\"Duration (Months and Days)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d3d964238ddfab4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter for durations up to 60 months (5 years)\n",
    "threshold_seconds = 60 * 30 * 24 * 3600  # 60 months in seconds\n",
    "filtered_times = [t for t in times if t <= threshold_seconds]\n",
    "excluded_count = len(times) - len(filtered_times)\n",
    "\n",
    "# Define bin edges for 6-month intervals\n",
    "bin_edges = np.arange(0, threshold_seconds + 1, 6 * 30 * 24 * 3600)  # 6 months per bin\n",
    "\n",
    "# Create the histogram for filtered times with custom colors\n",
    "hist, _, patches = plt.hist(filtered_times, bins=bin_edges, edgecolor='black', color='orange')\n",
    "\n",
    "# Annotate with the number of cases\n",
    "for i, count in enumerate(hist):\n",
    "    plt.text(bin_edges[i] + (bin_edges[i + 1] - bin_edges[i]) / 2,  # Position at bin center\n",
    "             count + 1,  # Slightly above the bar\n",
    "             int(count),  # Case count as text\n",
    "             ha='center', fontsize=8)\n",
    "\n",
    "# Format x-axis with custom labels\n",
    "def format_duration(seconds):\n",
    "    months = seconds / (30 * 24 * 3600)\n",
    "    return f\"{int(months)} months\"\n",
    "\n",
    "# Create bin labels for 6-month intervals\n",
    "bin_labels = [format_duration(edge) for edge in bin_edges]\n",
    "\n",
    "# Set the x-ticks and labels\n",
    "plt.xticks(ticks=bin_edges, labels=bin_labels, rotation=45, fontsize=8)\n",
    "\n",
    "plt.title(\"Trace Duration Distribution (Up to 60 Months)\")\n",
    "plt.xlabel(\"Duration (Months)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print case counts\n",
    "print(f\"Total cases included in the histogram: {len(filtered_times)}\")\n",
    "print(f\"Number of cases longer than 60 months: {excluded_count}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b4b43f3215077c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Discover event attributes, start activities, and end activities\n",
    "event_attributes = pm4py.get_event_attributes(log)\n",
    "\n",
    "print(event_attributes)\n",
    "\n",
    "\n",
    "\n",
    "# Discover the Directly Follows Graph (DFG)\n",
    "dfg, start_activities, end_activities = pm4py.discover_dfg(log)\n",
    "print(type(dfg))\n",
    "print(len(dfg))\n",
    "\n",
    "# Visualize the filtered DFG\n",
    "pm4py.view_dfg(dfg, start_activities=start_activities, end_activities=end_activities)\n",
    "\n",
    "# Set a threshold value (e.g., only keep transitions with a frequency greater than 1000)\n",
    "threshold = len(log)*0.025\n",
    "print(threshold)\n",
    "filtered_dfg = {k: v for k, v in dfg.items() if v > threshold}\n",
    "\n",
    "# Now visualize the filtered DFG\n",
    "pm4py.view_dfg(filtered_dfg, start_activities=start_activities, end_activities=end_activities, max_num_edges=100)\n",
    "\n",
    "# Print event attributes\n",
    "print(\"Event Attributes:\", event_attributes)\n",
    "\n",
    "for event_attribute in event_attributes:\n",
    "    event_attributes_values = pm4py.get_event_attribute_values(log, event_attribute)\n",
    "    print(event_attributes_values)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84412fd6beaf6d1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "\n",
    "# Step 1: Get all possible consecutive event pairs (Directly Follows)\n",
    "dfg = pm4py.discover_dfg(log)\n",
    "\n",
    "# Step 2: Collect the timestamps for consecutive events\n",
    "# We'll collect the timestamps for each consecutive event pair and calculate the time difference\n",
    "event_pairs = []\n",
    "\n",
    "for trace in log:\n",
    "    for i in range(len(trace) - 1):\n",
    "        # Get the current event and the next event\n",
    "        current_event = trace[i]\n",
    "        next_event = trace[i + 1]\n",
    "        \n",
    "        # Get timestamps of the current event and next event\n",
    "        current_time = current_event['time:timestamp']\n",
    "        next_time = next_event['time:timestamp']\n",
    "        \n",
    "        # Calculate the time difference in seconds\n",
    "        time_diff = (next_time - current_time).total_seconds()  # In seconds\n",
    "        \n",
    "        # Append the event pair and time difference\n",
    "        event_pairs.append(((current_event['concept:name'], next_event['concept:name']), time_diff))\n",
    "\n",
    "# Convert the event pairs list to a DataFrame for better analysis\n",
    "df = pd.DataFrame(event_pairs, columns=['Event Pair', 'Time Diff (seconds)'])\n",
    "\n",
    "# Step 3: Compute statistical measures for each event pair\n",
    "# Function to convert seconds into years, months, and days\n",
    "def format_duration(seconds):\n",
    "    # Convert seconds to years, months, and days\n",
    "    years = seconds // (365 * 24 * 3600)  # Approximation: 1 year = 365 days\n",
    "    months = (seconds % (365 * 24 * 3600)) // (30 * 24 * 3600)  # Approximation: 1 month = 30 days\n",
    "    days = (seconds % (30 * 24 * 3600)) // (24 * 3600)\n",
    "    return f\"{int(years)}y {int(months)}m {int(days)}d\"\n",
    "\n",
    "# Calculate statistical measures for each event pair\n",
    "stats = df.groupby('Event Pair')['Time Diff (seconds)'].agg(['mean', 'median', 'min', 'max', 'std'])\n",
    "\n",
    "# Replace NaN values with 0 won't work... we have to delete them\n",
    "stats.dropna(inplace = True)\n",
    "\n",
    "# Convert the time statistics to years, months, and days for better readability\n",
    "for stat in ['mean', 'median', 'min', 'max', 'std']:\n",
    "    # Convert seconds to integers before formatting\n",
    "    stats[stat] = stats[stat].apply(lambda x: format_duration(x) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Print the statistics for each event pair\n",
    "print(stats)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95273bbb277e68cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7b78308619cc4f0b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
